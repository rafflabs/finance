# -*- coding: utf-8 -*-
"""portafogli volatilita.ipynb
import numpy as np
import pandas as pd
import yfinance as yf
import matplotlib.pyplot as plt
plt.style.use("seaborn")
import seaborn
import datetime
import random

"""# Analisi su indici"""

# TO DO: AGGIUNGERE UNA DESCRIZIONE DELLO SCOPO DEL FILE

indici = [["S&P500", "^GSPC"], ["FTSE UK", "^FTSE"], ["Russell 2000 USA small caps", "^RUT"],
          ["STOXX 50 Europa", "^STOXX50E"], ["Nikkei Giaoppone", "^N225"], ["Hang Seng HK", "^HSI"],
          ["SSE composite Cina", "000001.SS"], ["Bond US 1 anno", "^IRX"], ["Bond US 10 anni", "^TNX"]] 
bond_tickers = ["^IRX", "^TNX"]
indici.append(["Bitcoin", "BTC-EUR"])

nomi = list(np.array(indici)[:,0])
tickers = list(np.array(indici)[:,1])

dati = yf.download(tickers)["Adj Close"]

# rimetto a posto le colonne che non ho capito perchÃ© me le scombina
dati = dati.reindex(tickers, axis=1)

dati.info()

dati

for c in dati.columns:
  plt.figure()
  plt.title(c)
  dati[c].plot(figsize=(20,10))
  plt.show()

# riempio i missing di al massimo una settimana
dati.ffill(limit=5, inplace=True)

rendimenti = dati.pct_change(1)
# DEVO SISTEMARE I DATI SULLE OBBLIGAZIONI CHE NON SONO I PREZZI MA I RENDIMENTI!!!
rendimenti[bond_tickers] = (1 + dati[bond_tickers]/100)**(1/253) - 1

(rendimenti.mean() + 1)**253 - 1

plt.figure(figsize=(13,8))
#seaborn.set(font_scale=1.2)
seaborn.heatmap(rendimenti.corr(),cmap="Reds", annot=True, annot_kws={"size":12})

# se io volessi analizzare tutti i portafogli equally weighted di N etf, quanti casi dovrei analizzare?
x = np.math.factorial(len(dati.columns))
for i in range(2, len(dati.columns)):
  print(i, x/np.math.factorial(len(dati.columns)-i))

quante = 10000
cov = rendimenti.cov() * 100 * 253
medie = ((rendimenti.mean() + 1)**253 - 1) * 100
tabella = pd.DataFrame(columns=["rendimento","varianza","quasi Sharpe"] + nomi)
tabella1 = pd.DataFrame(columns=["rendimento","varianza","quasi Sharpe"]+nomi)
for k in range(len(dati.columns)):
  w = np.zeros(len(dati.columns))
  w[k] = 1.00
  w = w / sum(w)
  rend = np.dot(medie, w)
  vol = np.dot(w, np.dot(cov, w))
  tabella1.loc[k] = [rend, vol, rend/vol] + list(w*100)

for k in range(quante):
#  w = np.random.random(len(dati.columns))
  w = np.random.normal(1, 0.2, len(dati.columns))
  w[w>1] = w[w>1] - 1
  w = w / sum(w)
  rend = np.dot(medie, w)
  vol = np.dot(w, np.dot(cov, w))
  tabella.loc[k] = [rend, vol, rend/vol] + list(w*100)
  if k % 1000 == 0:
    print(k)

ax = tabella.plot.scatter(x="varianza", y="rendimento", figsize=(20,9), fontsize=12, s=1, color="r")
axes = plt.gca()
x = axes.get_xlim()
y = axes.get_ylim()
tabella1.plot.scatter(ax=ax, x="varianza", y="rendimento", figsize=(20,9), fontsize=12, s=3, color="g", xlim=x, ylim=y)
for i in tabella.index:
    plt.annotate(i, xy=(tabella.loc[i,"varianza"], tabella.loc[i,"rendimento"]), size=8)
for i in tabella1.index:
    plt.annotate(i, xy=(tabella1.loc[i,"varianza"], tabella1.loc[i,"rendimento"]), size=8)

tabella.loc[9594]

tabella1

tabella["rendimento"].idxmax(),tabella.loc[tabella["rendimento"].idxmax()]

tabella["varianza"].idxmin(),tabella.loc[tabella["varianza"].idxmin()]

tabella["quasi Sharpe"].idxmax(),tabella.loc[tabella["quasi Sharpe"].idxmax()]

"""# Analisi su ETF azionari geografici"""

# escludo: replica swap, leva, settoriali, ESG e similari, strategie di trading, sotto 100M di capitalizzazione, identici ad altri indici
# =======================================================================================================================================
etf=[["iShares Core S&P 500","CSSPX",0.07,False],["iShares Core MSCI World","SWDA",0.20,True],["iShares Core MSCI Emerging Markets IMI","EIMI",0.18,True],
     ["iShares Nasdaq 100","CSNDX",0.33,False],["iShares MSCI ACWI","IUSQ",0.20,True],["Vanguard FTSE All-World","VWCE",0.22,True],
     ["iShares Core DAX","EXS1",0.16,False],["Lyxor Core STOXX Europe 600 (DR)","MEUD",0.07,True],["iShares Core MSCI Europe","SMEA",0.12,True],
     ["Xtrackers MSCI USA","XD9U",0.07,False],["Xtrackers MSCI Emerging Markets","XMME",0.18,True],["iShares Core EURO STOXX 50","CSSX5E",0.10,True],
     ["iShares Edge MSCI World Value Factor","IWVL",0.30,True],["iShares Core MSCI Japan IMI","SJPA",0.15,False],["iShares Core MSCI EMU","CSEMU",0.12,True],
     ["iShares Edge MSCI World Minimum Volatility","MVOL",0.30,True],["iShares Edge MSCI Europe Value Factor","IEVL",0.25,True],["iShares MSCI China A","36BZ",0.40,False],
     ["iShares Core MSCI Pacific ex Japan","CSPXJ",0.20,True],["Xtrackers S&P 500 Equal Weight","XDEW",0.20,False],["iShares MSCI World Small Cap","IUSN",0.35,True],
     ["iShares Edge MSCI World Quality Factor","IWQU",0.30,True],["iShares MSCI EM Asia","CSEMAS",0.20,True],["UBS ETF (LU) MSCI UK","UKGBPB",0.20,False],
     ["SPDR S&P 400 US Mid Cap","SPY4",0.30,False],["iShares Edge S&P 500 Minimum Volatility","MVUS",0.20,False],["iShares MSCI India","QDV5",0.65,False],
     ["UBS ETF (LU) MSCI Switzerland 20/35","SW2CHB",0.20,False],["SPDR Russell 2000 US Small Cap","R2US",0.30,False],["iShares MSCI Canada","CSCA",0.48,False],
     ["Xtrackers MSCI China","XCS6",0.65,False],["Amundi CAC 40","C40",0.25,False],["Xtrackers MSCI Europe Small Cap","XXSC",0.30,True],
     ["Vanguard FTSE North America","VNRA",0.10,True],["Amundi ETF MSCI Europe Value Factor","VCEU",0.23,True],["Amundi MSCI Europe Quality Factor","QCEU",0.23,True],
     ["iShares MSCI Australia","SAUS",0.50,False],["Amundi ETF MSCI World ex EMU","CM9",0.35,True],["Shares MSCI Saudi Arabia Capped","IUSS",0.60,False],
     ["Franklin FTSE Korea","FLXK",0.09,False],["WisdomTree US Quality Dividend Growth","DGRA",0.33,False],["Lyxor MSCI Brazil","BRA",0.65,False],
     ["Lyxor MSCI Emerging Markets Ex China","EMXC",0.15,True],["Vanguard FTSE Emerging Markets","VFEA",0.22,True],["iShares Edge MSCI World Size Factor","IWSZ",0.30,False],
     ["Amundi Japan Topix","XAMY",0.20,False],["Vanguard FTSE Developed Europe ex UK","VERE",0.10,False],["Fidelity US Quality Income","FUSA",0.25,False],
     ["Franklin FTSE China","FLXC",0.19,False],["iShares MSCI UK Small Cap","SXRD",0.58,False],["Franklin FTSE India","FLXI",0.19,False],
     ["iShares Nikkei 225","CSNKY",0.48,False],["Amundi MSCI Nordic","CN1",0.25,False],["iShares Edge MSCI Europe Multifactor","IFSE",0.45,True],
     ["Amundi MSCI Europe Minimum Volatility Factor","MIVO",0.23,True],["iShares MSCI EMU Large Cap","EMUL",0.49,True],["Xtrackers MSCI North America High Dividend Yield","XDND",0.39,False],
     ["Amundi ETF MSCI Switzerland","18MN",0.25,False],["iShares MSCI EMU Mid Cap","IS3H",0.49,True],["iShares MSCI Korea","CSKR",0.65,False],
     ["SPDR MSCI Europe Small Cap","SMCX",0.30,True],["Xtrackers MSCI Mexico","XMEX",0.65,False],["Lyxor MSCI Eastern Europe ex Russia","EST",0.50,False],
     ["iShares Edge MSCI USA Size Factor","QDVC",0.20,False],["SPDR MSCI USA Value Weighted","ZPRU",0.20,False],["Xtrackers MSCI Taiwan","XMTW",0.65,False]]

# da esludere: tutti quelli che pur avendo un indice diverso si sovrappongono e tutti quelli globali che hanno sotto coperto da altri con ter dignitosi e quelli "excluding" se non servono
# ====================================================================================================================================================================
etf=[["iShares Core S&P 500","CSSPX",0.07,False],["iShares Nasdaq 100","CSNDX",0.33,False],["iShares Core DAX","EXS1",0.16,False],["iShares Core MSCI Japan IMI","SJPA",0.15,False],
     ["iShares Edge MSCI Europe Value Factor","IEVL",0.25,True],["iShares MSCI China A","36BZ",0.40,False],["iShares Core MSCI Pacific ex Japan","CSPXJ",0.20,True],
     ["Xtrackers S&P 500 Equal Weight","XDEW",0.20,False],["UBS ETF (LU) MSCI UK","UKGBPB",0.20,False],
     ["SPDR S&P 400 US Mid Cap","SPY4",0.30,False],["iShares Edge S&P 500 Minimum Volatility","MVUS",0.20,False],["iShares MSCI India","QDV5",0.65,False],
     ["UBS ETF (LU) MSCI Switzerland 20/35","SW2CHB",0.20,False],["SPDR Russell 2000 US Small Cap","R2US",0.30,False],["iShares MSCI Canada","CSCA",0.48,False],["Amundi CAC 40","C40",0.25,False],["Xtrackers MSCI Europe Small Cap","XXSC",0.30,True],
     ["Amundi ETF MSCI Europe Value Factor","VCEU",0.23,True],["Amundi MSCI Europe Quality Factor","QCEU",0.23,True],["iShares MSCI Australia","SAUS",0.50,False],
     ["Shares MSCI Saudi Arabia Capped","IUSS",0.60,False],["Franklin FTSE Korea","FLXK",0.09,False],["WisdomTree US Quality Dividend Growth","DGRA",0.33,False],
     ["Lyxor MSCI Brazil","BRA",0.65,False],["iShares MSCI UK Small Cap","SXRD",0.58,False],["Amundi MSCI Nordic","CN1",0.25,False],
     ["Amundi MSCI Europe Minimum Volatility Factor","MIVO",0.23,True],["iShares MSCI EMU Large Cap","EMUL",0.49,True],["Xtrackers MSCI North America High Dividend Yield","XDND",0.39,False],
     ["iShares MSCI EMU Mid Cap","IS3H",0.49,True],["Xtrackers MSCI Mexico","XMEX",0.65,False],["Lyxor MSCI Eastern Europe ex Russia","EST",0.50,False],["iShares Edge MSCI USA Size Factor","QDVC",0.20,False],
     ["SPDR MSCI USA Value Weighted","ZPRU",0.20,False],["Xtrackers MSCI Taiwan","XMTW",0.65,False]]

# escludiamo anche le versioni su base di criteri contabili e quelle lievemente sovrapposte (addio Nasdaq), tengo solo le small caps Russell
# ==========================================================================================================================================
etf=[["iShares Core S&P 500","CSSPX",0.07,False],["iShares Core DAX","EXS1",0.16,False],["iShares Core MSCI Japan IMI","SJPA",0.15,False],
     ["iShares MSCI China A","36BZ",0.40,False],["UBS ETF (LU) MSCI UK","UKGBPB",0.20,False],["iShares MSCI India","QDV5",0.65,False],
     ["UBS ETF (LU) MSCI Switzerland 20/35","SW2CHB",0.20,False],["SPDR Russell 2000 US Small Cap","R2US",0.30,False],["iShares MSCI Canada","CSCA",0.48,False],
     ["Amundi CAC 40","C40",0.25,False],["iShares MSCI Australia","SAUS",0.50,False],["Shares MSCI Saudi Arabia Capped","IUSS",0.60,False],["Franklin FTSE Korea","FLXK",0.09,False],["Lyxor MSCI Brazil","BRA",0.65,False],
     ["Amundi MSCI Nordic","CN1",0.25,False],["Xtrackers MSCI Mexico","XMEX",0.65,False],["Lyxor MSCI Eastern Europe ex Russia","EST",0.50,False],
     ["Xtrackers MSCI Taiwan","XMTW",0.65,False]]

nomi = list(np.array(etf)[:,0])
tickers = list(np.array(etf)[:,1])
ter = list(np.array(etf)[:,2])
globali = list(np.array(etf)[:,3])
tickersMI = [t + ".MI" for t in tickers]
tickersF = [t + ".F" for t in tickers]
tickersPA = [t + ".PA" for t in tickers]

datiMI = yf.download(tickersMI)["Adj Close"]
datiF = yf.download(tickersF)["Adj Close"]
datiPA = yf.download(tickersPA)["Adj Close"]

# rimetto a posto le colonne che non ho capito perchÃ© me le scombina
datiMI = datiMI.reindex(tickersMI, axis=1)
datiPA = datiPA.reindex(tickersPA, axis=1)
datiF = datiF.reindex(tickersF, axis=1)

# cambio i nomi alle colonne mettendoli uguali
datiMI.rename(columns = dict(zip(tickersMI, tickers)),inplace=True)
datiF.rename(columns = dict(zip(tickersF, tickers)),inplace=True)
datiPA.rename(columns = dict(zip(tickersPA, tickers)),inplace=True)

# stesso indice per tutti!
dati = datiMI.reindex( index=datiMI.index.union(datiPA.index).union(datiF.index) )
datiPA = datiPA.reindex( index=dati.index )
datiF = datiF.reindex( index=dati.index )

# BRA.F non Ã¨ BRA.MI.... 'azzo di tickers e chi li ha inventati!
if "BRA" in tickers:
  datiF["BRA"] = np.nan

# mi vergogno di questo pezzo qui sotto...
for i in dati.index:
  for c in dati:
    if np.isnan(dati[c].loc[i]):
      if not np.isnan(datiF[c].loc[i]):
        dati[c].loc[i] = datiF[c].loc[i]
      elif not np.isnan(datiPA[c].loc[i]):
        dati[c].loc[i] = datiPA[c].loc[i]
dati

dati.info()

for c in dati.columns:
  plt.figure()
  plt.title(c)
  dati[c].plot(figsize=(20,9))
  plt.show()

"""36BZ -> da 6-2018

CSCA -> da 3-2010

SW2CHB -> da 1-2017



"""

if "36BZ" in dati.columns:
  dati["36BZ"].loc[:pd.to_datetime("2018-06-01")]=np.nan
if "CSCA" in dati.columns:
  dati["CSCA"].loc[:pd.to_datetime("2010-03-01")]=np.nan
if "SW2CHB" in dati.columns:
  dati["SW2CHB"].loc[:pd.to_datetime("2017-01-01")]=np.nan

# riempio i missing di al massimo una settimana
dati.ffill(limit=5, inplace=True)

rendimenti = dati.pct_change(1)
(rendimenti.mean() + 1)**253 - 1

plt.figure(figsize=(13,8))
#seaborn.set(font_scale=1.2)
seaborn.heatmap(rendimenti.corr(),cmap="Reds", annot=True, annot_kws={"size":12})

# se io volessi analizzare tutti i portafogli equally weighted di N etf, quanti casi dovrei analizzare?
x = np.math.factorial(len(dati.columns))
for i in range(2,len(dati.columns)):
  print(i, x/np.math.factorial(len(dati.columns) - i))

quante = 10000
cov = rendimenti.cov()*100*253
medie = ((rendimenti.mean()+1)**253 - 1) * 100
tabella = pd.DataFrame(columns=["rendimento","varianza","quasi Sharpe"]+nomi)
tabella1 = pd.DataFrame(columns=["rendimento","varianza","quasi Sharpe"]+nomi)

for k in range(len(dati.columns)):
  w = np.zeros(len(dati.columns))
  w[k] = 1.00
  w = w / sum(w)
  rend = np.dot(medie,w)
  vol = np.dot(w, np.dot(cov,w))
  tabella1.loc[k] = [rend,vol,rend/vol] + list(w*100)

for k in range(quante):
#  w = np.random.random(len(dati.columns))
  w = np.random.normal(1, 0.2, len(dati.columns))
  w[w>1] = w[w>1]-1
  w = w / sum(w)
  rend = np.dot(medie,w)
  vol = np.dot(w,np.dot(cov,w))
  tabella.loc[k] = [rend,vol,rend/vol] + list(w*100)
  if k % 1000 == 0:
    print(k)

ax = tabella.loc[len(dati.columns):].plot.scatter(x="varianza", y="rendimento", figsize=(20,9), fontsize=12, s=1, color="r")
axes = plt.gca()
x = axes.get_xlim()
y = axes.get_ylim()
tabella.loc[:len(dati.columns)].plot.scatter(ax=ax, x="varianza", y="rendimento", figsize=(20,9), fontsize=12, s=3, color="g", xlim=x, ylim=y)
for i in tabella.index:
    plt.annotate(i, xy=(tabella.loc[i,"varianza"],tabella.loc[i,"rendimento"]), size=8)
for i in tabella1.index:
    plt.annotate(i, xy=(tabella1.loc[i,"varianza"],tabella1.loc[i,"rendimento"]), size=8)

tabella1

tabella.loc[7888]

tabella["rendimento"].idxmax(),tabella.loc[tabella["rendimento"].idxmax()]

tabella["varianza"].idxmin(),tabella.loc[tabella["varianza"].idxmin()]

tabella["quasi Sharpe"].idxmax(),tabella.loc[tabella["quasi Sharpe"].idxmax()]

"""# Analisi su ETF per asset class"""

etf=[["iShares MSCI North America","INAA"],["iShares STOXX Europe 600","EXSA"],
     ["Lyxor MSCI Emerging Markets Ex China","EMXC"],["iShares MSCI China A","36BZ"],
     ["Vanguard USD Treasury Bond","VDTA"],
     ["Xtrackers Eurozone Government Bond","XGLE"],["iShares Euro Inflation Linked Government Bond","IBCI"],["Xtrackers II EUR Corporate Bond","XBLC"],
     ["Invesco Physical Gold","SGLD"],["Invesco Bloomberg Commodity","CMOD"],["ETC Group Physical Bitcoin","BTCE"],
     ["iShares Developed Markets Property Yield","IWDP"]] 

nomi = list(np.array(etf)[:,0])
tickers = list(np.array(etf)[:,1])
tickersMI = [t + ".MI" for t in tickers]
tickersF = [t + ".F" for t in tickers]
tickersPA = [t + ".PA" for t in tickers]

datiMI = yf.download(tickersMI)["Adj Close"]
datiF = yf.download(tickersF)["Adj Close"]
datiPA = yf.download(tickersPA)["Adj Close"]

# rimetto a posto le colonne che non ho capito perchÃ© me le scombina
datiMI = datiMI.reindex(tickersMI, axis=1)
datiPA = datiPA.reindex(tickersPA, axis=1)
datiF = datiF.reindex(tickersF, axis=1)
# cambio i nomi alle colonne mettendoli uguali
datiMI.rename(columns=dict(zip(tickersMI, tickers)), inplace=True)
datiF.rename(columns=dict(zip(tickersF, tickers)), inplace=True)
datiPA.rename(columns=dict(zip(tickersPA, tickers)), inplace=True)
# stesso indice per tutti!
dati = datiMI.reindex( index=datiMI.index.union(datiPA.index).union(datiF.index) )
datiPA = datiPA.reindex(index=dati.index)
datiF = datiF.reindex(index=dati.index)

# BRA.F non Ã¨ BRA.MI.... 'azzo di tickers e chi li ha inventati!
if "BRA" in tickers:
  datiF["BRA"] = np.nan

# mi vergogno di questo pezzo qui sotto...
for i in dati.index:
  for c in dati:
    if np.isnan(dati[c].loc[i]):
      if not np.isnan(datiF[c].loc[i]):
        dati[c].loc[i] = datiF[c].loc[i]
      elif not np.isnan(datiPA[c].loc[i]):
        dati[c].loc[i] = datiPA[c].loc[i]
dati

dati.info()

for c in dati.columns:
  plt.figure()
  plt.title(c)
  dati[c].plot(figsize=(20,9))
  plt.show()

"""36BZ -> da 6-2018

EXSA -> da 1-2013

CMOD -> da 9-2017


"""

if "36BZ" in dati.columns:
  dati["36BZ"].loc[:pd.to_datetime("2018-06-01")] = np.nan
if "EXSA" in dati.columns:
  dati["EXSA"].loc[:pd.to_datetime("2013-01-01")] = np.nan
if "CMOD" in dati.columns:
  dati["CMOD"].loc[:pd.to_datetime("2017-09-01")] = np.nan

# riempio i missing di al massimo una settimana
dati.ffill(limit=5, inplace=True)

rendimenti = dati.pct_change(1)
(rendimenti.mean()+1)**253-1

plt.figure(figsize=(13,8))
#seaborn.set(font_scale=1.2)
seaborn.heatmap(rendimenti.corr(),cmap="Reds", annot=True, annot_kws={"size":12})

# se io volessi analizzare tutti i portafogli equally weighted di N etf, quanti casi dovrei analizzare?
x=np.math.factorial(len(dati.columns))
for i in range(2, len(dati.columns)):
  print(i, x/np.math.factorial(len(dati.columns)-i))

quante = 10000
cov = rendimenti.cov()*100*253
medie = ((rendimenti.mean()+1)**253-1)*100
tabella = pd.DataFrame(columns=["rendimento","varianza","quasi Sharpe"]+nomi)
tabella1 = pd.DataFrame(columns=["rendimento","varianza","quasi Sharpe"]+nomi)
for k in range(len(dati.columns)):
  w = np.zeros(len(dati.columns))
  w[k] = 1.00
  w = w / sum(w)
  rend = np.dot(medie,w)
  vol = np.dot(w, np.dot(cov,w))
  tabella1.loc[k] = [rend,vol,rend/vol]+list(w*100)

for k in range(quante):
#  w = np.random.random(len(dati.columns))
  w = np.random.normal(1,0.2,len(dati.columns))
  w[w>1] = w[w>1]-1
  w = w / sum(w)
  rend = np.dot(medie, w)
  vol = np.dot(w, np.dot(cov, w))
  tabella.loc[k] = [rend,vol,rend/vol]+list(w*100)
  if k%1000 == 0:
    print(k)

ax = tabella.plot.scatter(x="varianza",y="rendimento", figsize=(20,9),fontsize=12,s=1,color="r")
axes = plt.gca()
x = axes.get_xlim()
y = axes.get_ylim()
tabella1.plot.scatter(ax=ax,x="varianza",y="rendimento", figsize=(20,9),fontsize=12,s=3,color="g",xlim=x,ylim=y)
for i in tabella.index:
    plt.annotate(i,xy=(tabella.loc[i,"varianza"],tabella.loc[i,"rendimento"]),size=8)
for i in tabella1.index:
    plt.annotate(i,xy=(tabella1.loc[i,"varianza"],tabella1.loc[i,"rendimento"]),size=8)

tabella1

tabella.loc[8083]

tabella["rendimento"].idxmax(),tabella.loc[tabella["rendimento"].idxmax()]

tabella["varianza"].idxmin(),tabella.loc[tabella["varianza"].idxmin()]

tabella["quasi Sharpe"].idxmax(),tabella.loc[tabella["quasi Sharpe"].idxmax()]

"""# Il mio portafoglio"""

etf=[["iShares MSCI North America","INAA"],["iShares STOXX Europe 600","EXSA"],
     ["Lyxor MSCI Emerging Markets Ex China","EMXC"],["iShares MSCI China A","36BZ"],
     ["Vanguard USD Treasury Bond","VDTA"],
     ["Xtrackers Eurozone Government Bond","XGLE"],["iShares Euro Inflation Linked Government Bond","IBCI"],["Xtrackers II EUR Corporate Bond","XBLC"],
     ["Invesco Physical Gold","SGLD"],["Invesco Bloomberg Commodity","CMOD"],["ETC Group Physical Bitcoin","BTCE"],
     ["iShares Developed Markets Property Yield","IWDP"]] 

nomi = list(np.array(etf)[:,0])
tickers = list(np.array(etf)[:,1])
tickersMI = [t + ".MI" for t in tickers]
tickersF = [t + ".F" for t in tickers]
tickersPA = [t + ".PA" for t in tickers]

datiMI = yf.download(tickersMI)["Adj Close"]
datiF = yf.download(tickersF)["Adj Close"]
datiPA = yf.download(tickersPA)["Adj Close"]

# rimetto a posto le colonne che non ho capito perchÃ© me le scombina
datiMI = datiMI.reindex(tickersMI, axis=1)
datiPA = datiPA.reindex(tickersPA, axis=1)
datiF = datiF.reindex(tickersF, axis=1)

# cambio i nomi alle colonne mettendoli uguali
datiMI.rename(columns = dict(zip(tickersMI, tickers)), inplace=True)
datiF.rename(columns = dict(zip(tickersF, tickers)), inplace=True)
datiPA.rename(columns = dict(zip(tickersPA, tickers)), inplace=True)

# stesso indice per tutti!
dati = datiMI.reindex( index=datiMI.index.union(datiPA.index).union(datiF.index) )
datiPA = datiPA.reindex( index=dati.index )
datiF = datiF.reindex( index=dati.index )

# BRA.F non Ã¨ BRA.MI.... 'azzo di tickers e chi li ha inventati!
if "BRA" in tickers:
  datiF["BRA"]=np.nan

# mi vergogno di questo pezzo qui sotto...
for i in dati.index:
  for c in dati:
    if np.isnan(dati[c].loc[i]):
      if not np.isnan(datiF[c].loc[i]):
        dati[c].loc[i] = datiF[c].loc[i]
      elif not np.isnan(datiPA[c].loc[i]):
        dati[c].loc[i] = datiPA[c].loc[i]
dati

dati.info()

for c in dati.columns:
  plt.figure()
  plt.title(c)
  dati[c].plot(figsize=(20,9))
  plt.show()

"""36BZ -> da 6-2018

EXSA -> da 1-2013

CMOD -> da 9-2017


"""

if "36BZ" in dati.columns:
  dati["36BZ"].loc[:pd.to_datetime("2018-06-01")] = np.nan
if "EXSA" in dati.columns:
  dati["EXSA"].loc[:pd.to_datetime("2013-01-01")] = np.nan
if "CMOD" in dati.columns:
  dati["CMOD"].loc[:pd.to_datetime("2017-09-01")] = np.nan

# riempio i missing di al massimo una settimana
dati.ffill(limit=5,inplace=True)

rendimenti = dati.pct_change(1)
(rendimenti.mean()+1)**253-1

plt.figure(figsize=(13,8))
#seaborn.set(font_scale=1.2)
seaborn.heatmap(rendimenti.corr(),cmap="Reds", annot=True, annot_kws={"size":12})

# se io volessi analizzare tutti i portafogli equally weighted di N etf, quanti casi dovrei analizzare?
x=np.math.factorial(len(dati.columns))
for i in range(2,len(dati.columns)):
  print(i,x/np.math.factorial(len(dati.columns)-i))

quante=10000
cov = rendimenti.cov()*100*253
medie = ((rendimenti.mean()+1)**253-1)*100
tabella = pd.DataFrame(columns=["rendimento","varianza","quasi Sharpe"]+nomi)
tabella1 = pd.DataFrame(columns=["rendimento","varianza","quasi Sharpe"]+nomi)
for k in range(len(dati.columns)):
  w = np.zeros(len(dati.columns))
  w[k] = 1.00
  w = w / sum(w)
  rend = np.dot(medie,w)
  vol = np.dot(w,np.dot(cov,w))
  tabella1.loc[k] = [rend,vol,rend/vol]+list(w*100)
for k in range(quante):
#  w = np.random.random(len(dati.columns))
  w = np.random.normal(1,0.2,len(dati.columns))
  w[w>1] = w[w>1]-1
  w = w / sum(w)
  rend = np.dot(medie,w)
  vol = np.dot(w,np.dot(cov,w))
  tabella.loc[k] = [rend,vol,rend/vol]+list(w*100)
  if k%1000 == 0:
    print(k)

ax = tabella.plot.scatter(x="varianza",y="rendimento", figsize=(20,9),fontsize=12,s=1,color="r")
axes = plt.gca()
x = axes.get_xlim()
y = axes.get_ylim()
tabella1.plot.scatter(ax=ax,x="varianza",y="rendimento", figsize=(20,9),fontsize=12,s=3,color="g",xlim=x,ylim=y)
for i in tabella.index:
    plt.annotate(i,xy=(tabella.loc[i,"varianza"],tabella.loc[i,"rendimento"]),size=8)
for i in tabella1.index:
    plt.annotate(i,xy=(tabella1.loc[i,"varianza"],tabella1.loc[i,"rendimento"]),size=8)

tabella1

tabella.loc[8228]

tabella["rendimento"].idxmax(),tabella.loc[tabella["rendimento"].idxmax()]

tabella["varianza"].idxmin(),tabella.loc[tabella["varianza"].idxmin()]

tabella["quasi Sharpe"].idxmax(),tabella.loc[tabella["quasi Sharpe"].idxmax()]
